# Name of experiment. Must be unique for each experiment because experiment directory with the 
# same name is used.
exp_name=baseline

# GlobalPhone languages to be used throughout the experiment
GP_LANGUAGES="AR BG CH CR CZ FR GE JA KO PL PO RU SP SW TA TH TU WU VN"

# Starting stage, 1 being the first stage (not including the SHN->WAV pre-processing which should 
# only be done once, see run.sh.
stage=1

# Whether or not to run all the stages. Set to false to only run one specific stage, set to true to 
# run all stages, starting from the one set in the stage option.
run_all=false

# Directory in which to store raw WAV files of all GlobalPhone data used in experiments. Typically,
# you once convert the GlobalPhone SHN data into WAV, store them in this directory and take them
# from there in the feature computation part of any experiment.
wav_dir="$HOME/lid/wav"

# Experiment name (directory) from which to take the X-vector TDNN training examples. This way, 
# multiple experiments can share the same training examples, saving pre-processing time, storage
# space, and ensuring multiple experiments are run with the very same data. If not set, 
# data pre-processing will run and generate own training data for this experiment. Should be an 
# experiment name such as 'baseline'.
use_dnn_egs_from=

# Feature type to use in training. Default is mfcc. Possible values: mfcc, mfcc_deltas, sdc, 
# pitch_energy, energy, pitch, sdc_pitch_energy, mfcc_deltas_pitch_energy, sdc_pitch, sdc_energy.
feature_type=mfcc

# Number of epochs to train the X-vector TDNN for.
num_epochs=7

# Source pre-processed features from other experiments to avoid unnecessary duplicated feature 
# computation. Also useful if you want to quickly combine any existing computed features. Currently,
# only absolute paths are supported, but in the future it should be possible to simply use 
# experiment names here, such as 'baseline'. TODO: add support for experiment names.
mfcc_dir=
mfcc_deltas_dir=
sdc_dir=
pitch_energy_dir=
energy_dir=
pitch_dir=

# Whether to use voice activity detection (VAD) for removing non-speech frames. Default: true. 
# Be careful with this one if you are combining different feature types. VAD can be computed 
# differently for each of them. It is recommended to compute VAD on one feature type and discard the
# same frames from any computed feature type (use the recompute_vad and exp_dir_for_vad options to 
# achieve this), otherwise the concatenation of multiple feature types may not work.
use_vad=true

# Whether to compute VAD over the features generated for this experiment. If false, vad.scp will be 
# taken from the mfcc experiment directory to ensure the same VAD filtering is applied to any 
# feature type. Note that re-computing VAD requires that the first number in each feature vector 
# acts as energy (or as C0 in MFCCs). Default: false
recompute_vad=false

# Experiment name to take vad.scp from. Make sure the other experiment uses the same eval_utt_len as
# your experiment (and, of course, the very same data).
exp_dir_for_vad=mfcc

# The experiment mode. Can be 'full', i.e. trying to run the whole experiment including feature 
# computation, training the X-vector TDNN and classifier and evaluating on evaluation (development) 
# data. An alternative is 'test_only' which translates to just computing test-set features, 
# producing their x-vectors, training the classifier and evaluating on test-set x-vectors.
mode=full

# The experiment from which the trained X-vector TDNN will be taken. Use for instance when  
# mode=test_only is set.
nnet_exp_dir=

# Max. length of eval and test speech segments. This splits any longer utterances, but does NOT 
# ensure that the average length is close to the set value (for this, you need to discard too short
# segments yourself).
eval_utt_len=10

# Whether to do feature computation, x-vector extraction and classification on the test set data or
# not. If false, then only the eval set is used.
use_test_set=false
