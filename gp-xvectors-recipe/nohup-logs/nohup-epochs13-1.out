Obtaining renewable credentials, you will be asked to type in your password
Password for s1513472@INF.ED.AC.UK: 
Running job "./run.sh --exp-config=conf/exp_configs/epochs13.conf --stage=4 --run-all=true" for maximum of 28 days in background
Waiting for job to start...
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 	 This shell script runs the GlobalPhone+X-vectors recipe.
 	 Use like this: ./run.sh <options>
 	 --stage=INT		Stage from which to start
 	 --run-all=(false|true)	Whether to run all stages
 	 			or just the specified one
 	 --experiment=STR	Experiment name (also name of directory 
 	 			where all files will be stored).
 	 			Default: 'baseline'.
 	 --exp-config=FILE	Config file with all kinds of options,
 	 			see conf/exp_default.conf for an example.
 	 			NOTE: Where arguments are passed on the command line,
 	 			the values overwrite those found in the config file.

 	 If no stage number is provided, either all stages
 	 will be run (--run-all=true) or no stages at all.
 +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Overwriting the experiment config value of run_all=true using the value 'true' passed as a command-line argument.
Overwriting the experiment config value of stage=4 using the value '4' passed as a command-line argument.
Running experiment: 'epochs13'
Running all stages starting with 4.
Running on the cluster.
Conda environment not activated, sourcing ~/.bashrc and activating the 'lid' env.
Using shorten (v3.6.1) from ~/language-ident-from-speech/gp-xvectors-recipe/tools/shorten-3.6.1/bin/shorten
Using sox (v14.3.2) from ~/language-ident-from-speech/gp-xvectors-recipe/tools/sox-14.3.2/bin/sox
Conda environment not activated, sourcing ~/.bashrc and activating the 'lid' env.
Using preprocessed data	from: /home/s1513472/lid/baseline
The experiment directory is: /home/s1513472/lid/epochs13
Running with languages: AR BG CH CR CZ FR GE JA KO PL PO RU SP SW TA TH TU WU VN
#### STAGE 4: Training the X-vector DNN. ####
Running on the cluster.
Conda environment 'lid' active.
Running on the cluster.
Taking data from: /home/s1513472/lid/baseline/nnet_train_data
Storing training examples in: /home/s1513472/lid/baseline/nnet/egs
Storing TDNN in: /home/s1513472/lid/epochs13/nnet
#### STAGE 6: Training the network. ####
2019-01-31 23:17:54,992 [steps/nnet3/train_raw_dnn.py:35 - <module> - INFO ] Starting raw DNN trainer (train_raw_dnn.py)
2019-01-31 23:17:55,224 [steps/nnet3/train_raw_dnn.py:156 - process_args - WARNING ] You are running with one thread but you have not compiled
                   for CUDA.  You may be running a setup optimized for GPUs.
                   If you have GPUs and have nvcc installed, go to src/ and do
                   ./configure; make
2019-01-31 23:17:55,225 [steps/nnet3/train_raw_dnn.py:195 - train - INFO ] Arguments for the experiment
{'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': None,
 'combine_sum_to_one_penalty': 0.0,
 'command': 'slurm.pl',
 'compute_average_posteriors': False,
 'compute_per_dim_accuracy': False,
 'dir': '/home/s1513472/lid/epochs13/nnet',
 'do_final_combination': True,
 'dropout_schedule': '0,0@0.20,0.1@0.50,0',
 'egs_command': None,
 'egs_dir': '/home/s1513472/lid/baseline/nnet/egs',
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': None,
 'final_effective_lrate': 0.0001,
 'frames_per_eg': 1,
 'image_augmentation_opts': None,
 'initial_effective_lrate': 0.001,
 'input_model': None,
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_objective_evaluations': 30,
 'max_param_change': 2.0,
 'minibatch_size': '64',
 'momentum': 0.5,
 'nj': 4,
 'num_epochs': 13.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 3,
 'num_jobs_initial': 3,
 'online_ivector_dir': None,
 'preserve_model_interval': 10,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 10.0,
 'rand_prune': 4.0,
 'remove_egs': False,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 1000,
 'srand': 123,
 'stage': 255,
 'targets_scp': None,
 'train_opts': [],
 'use_dense_targets': True,
 'use_gpu': 'yes'}
2019-01-31 23:17:55,370 [steps/nnet3/train_raw_dnn.py:353 - train - INFO ] Training will run for 13.0 epochs = 303 iterations
2019-01-31 23:17:55,371 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 255/302    Epoch: 10.93/13.0 (84.1% complete)    lr: 0.000433    shrink: 0.99567
Job started successfully
2019-01-31 23:24:50,128 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 256/302    Epoch: 10.97/13.0 (84.4% complete)    lr: 0.000430    shrink: 0.99570
2019-01-31 23:33:58,826 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 257/302    Epoch: 11.01/13.0 (84.7% complete)    lr: 0.000426    shrink: 0.99574
2019-01-31 23:41:48,964 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 258/302    Epoch: 11.06/13.0 (85.1% complete)    lr: 0.000423    shrink: 0.99577
2019-01-31 23:49:45,584 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 259/302    Epoch: 11.10/13.0 (85.4% complete)    lr: 0.000420    shrink: 0.99580
2019-01-31 23:55:32,632 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 260/302    Epoch: 11.14/13.0 (85.7% complete)    lr: 0.000417    shrink: 0.99583
2019-02-01 00:03:06,861 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 261/302    Epoch: 11.19/13.0 (86.0% complete)    lr: 0.000414    shrink: 0.99586
2019-02-01 00:10:48,073 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 262/302    Epoch: 11.23/13.0 (86.4% complete)    lr: 0.000411    shrink: 0.99589
2019-02-01 00:19:23,280 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 263/302    Epoch: 11.27/13.0 (86.7% complete)    lr: 0.000407    shrink: 0.99593
2019-02-01 00:28:40,214 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 264/302    Epoch: 11.31/13.0 (87.0% complete)    lr: 0.000404    shrink: 0.99596
2019-02-01 00:36:33,702 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 265/302    Epoch: 11.36/13.0 (87.4% complete)    lr: 0.000401    shrink: 0.99599
2019-02-01 00:43:08,032 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 266/302    Epoch: 11.40/13.0 (87.7% complete)    lr: 0.000398    shrink: 0.99602
2019-02-01 00:50:10,377 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 267/302    Epoch: 11.44/13.0 (88.0% complete)    lr: 0.000395    shrink: 0.99605
2019-02-01 00:57:15,261 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 268/302    Epoch: 11.49/13.0 (88.4% complete)    lr: 0.000392    shrink: 0.99608
2019-02-01 01:05:57,657 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 269/302    Epoch: 11.53/13.0 (88.7% complete)    lr: 0.000389    shrink: 0.99611
2019-02-01 01:14:36,877 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 270/302    Epoch: 11.57/13.0 (89.0% complete)    lr: 0.000386    shrink: 0.99614
2019-02-01 01:23:50,499 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 271/302    Epoch: 11.61/13.0 (89.3% complete)    lr: 0.000383    shrink: 0.99617
2019-02-01 01:31:11,268 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 272/302    Epoch: 11.66/13.0 (89.7% complete)    lr: 0.000381    shrink: 0.99619
2019-02-01 01:37:14,547 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 273/302    Epoch: 11.70/13.0 (90.0% complete)    lr: 0.000378    shrink: 0.99622
2019-02-01 01:45:23,746 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 274/302    Epoch: 11.74/13.0 (90.3% complete)    lr: 0.000375    shrink: 0.99625
2019-02-01 01:54:36,512 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 275/302    Epoch: 11.79/13.0 (90.7% complete)    lr: 0.000372    shrink: 0.99628
2019-02-01 02:02:16,693 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 276/302    Epoch: 11.83/13.0 (91.0% complete)    lr: 0.000369    shrink: 0.99631
2019-02-01 02:07:12,762 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 277/302    Epoch: 11.87/13.0 (91.3% complete)    lr: 0.000366    shrink: 0.99634
2019-02-01 02:14:26,112 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 278/302    Epoch: 11.91/13.0 (91.6% complete)    lr: 0.000364    shrink: 0.99636
2019-02-01 02:21:21,777 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 279/302    Epoch: 11.96/13.0 (92.0% complete)    lr: 0.000361    shrink: 0.99639
2019-02-01 02:29:08,984 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 280/302    Epoch: 12.00/13.0 (92.3% complete)    lr: 0.000358    shrink: 0.99642
2019-02-01 02:37:03,229 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 281/302    Epoch: 12.04/13.0 (92.6% complete)    lr: 0.000355    shrink: 0.99645
2019-02-01 02:44:55,841 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 282/302    Epoch: 12.09/13.0 (93.0% complete)    lr: 0.000353    shrink: 0.99647
2019-02-01 02:50:56,416 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 283/302    Epoch: 12.13/13.0 (93.3% complete)    lr: 0.000350    shrink: 0.99650
2019-02-01 02:58:10,860 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 284/302    Epoch: 12.17/13.0 (93.6% complete)    lr: 0.000347    shrink: 0.99653
2019-02-01 03:07:06,637 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 285/302    Epoch: 12.21/13.0 (94.0% complete)    lr: 0.000345    shrink: 0.99655
2019-02-01 03:15:05,643 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 286/302    Epoch: 12.26/13.0 (94.3% complete)    lr: 0.000342    shrink: 0.99658
2019-02-01 03:24:29,490 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 287/302    Epoch: 12.30/13.0 (94.6% complete)    lr: 0.000340    shrink: 0.99660
2019-02-01 03:32:27,351 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 288/302    Epoch: 12.34/13.0 (94.9% complete)    lr: 0.000337    shrink: 0.99663
2019-02-01 03:39:15,875 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 289/302    Epoch: 12.39/13.0 (95.3% complete)    lr: 0.000334    shrink: 0.99666
2019-02-01 03:46:23,505 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 290/302    Epoch: 12.43/13.0 (95.6% complete)    lr: 0.000332    shrink: 0.99668
2019-02-01 03:52:20,176 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 291/302    Epoch: 12.47/13.0 (95.9% complete)    lr: 0.000329    shrink: 0.99671
2019-02-01 03:59:23,407 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 292/302    Epoch: 12.51/13.0 (96.3% complete)    lr: 0.000327    shrink: 0.99673
2019-02-01 04:06:41,498 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 293/302    Epoch: 12.56/13.0 (96.6% complete)    lr: 0.000324    shrink: 0.99676
2019-02-01 04:16:02,762 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 294/302    Epoch: 12.60/13.0 (96.9% complete)    lr: 0.000322    shrink: 0.99678
2019-02-01 04:23:23,190 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 295/302    Epoch: 12.64/13.0 (97.3% complete)    lr: 0.000320    shrink: 0.99680
2019-02-01 04:30:39,165 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 296/302    Epoch: 12.69/13.0 (97.6% complete)    lr: 0.000317    shrink: 0.99683
2019-02-01 04:38:48,171 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 297/302    Epoch: 12.73/13.0 (97.9% complete)    lr: 0.000315    shrink: 0.99685
2019-02-01 04:46:45,168 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 298/302    Epoch: 12.77/13.0 (98.2% complete)    lr: 0.000312    shrink: 0.99688
2019-02-01 04:54:26,155 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 299/302    Epoch: 12.81/13.0 (98.6% complete)    lr: 0.000310    shrink: 0.99690
2019-02-01 04:59:19,937 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 300/302    Epoch: 12.86/13.0 (98.9% complete)    lr: 0.000308    shrink: 0.99692
2019-02-01 05:06:15,440 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 301/302    Epoch: 12.90/13.0 (99.2% complete)    lr: 0.000305    shrink: 0.99695
2019-02-01 05:13:30,048 [steps/nnet3/train_raw_dnn.py:388 - train - INFO ] Iter: 302/302    Epoch: 12.94/13.0 (99.6% complete)    lr: 0.000300    shrink: 0.99700
2019-02-01 05:21:31,677 [steps/nnet3/train_raw_dnn.py:440 - train - INFO ] Doing final combination to produce final.raw
2019-02-01 05:21:31,678 [steps/libs/nnet3/train/frame_level_objf/common.py:491 - combine_models - INFO ] Combining {284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303} models.
2019-02-01 05:25:47,557 [steps/nnet3/train_raw_dnn.py:462 - train - INFO ] Cleaning up the experiment directory /home/s1513472/lid/epochs13/nnet
/home/s1513472/lid/epochs13/nnet: num-iters=303 nj=3..3 num-params=4.5M dim=23->19 combine=-0.02->-0.02 (over 20) loglike:train/valid[201,302]=(-0.040,-0.031/-0.21,-0.129) accuracy:train/valid[201,302]=(1.0000,1.0000/0.922,0.961)
steps/nnet3/train_raw_dnn.py --stage=255 --cmd=slurm.pl --trainer.optimization.proportional-shrink 10 --trainer.optimization.momentum=0.5 --trainer.optimization.num-jobs-initial=3 --trainer.optimization.num-jobs-final=3 --trainer.optimization.initial-effective-lrate=0.001 --trainer.optimization.final-effective-lrate=0.0001 --trainer.optimization.minibatch-size=64 --trainer.srand=123 --trainer.max-param-change=2 --trainer.num-epochs=13 --trainer.dropout-schedule=0,0@0.20,0.1@0.50,0 --trainer.shuffle-buffer-size=1000 --egs.frames-per-eg=1 --egs.dir=/home/s1513472/lid/baseline/nnet/egs --cleanup.remove-egs false --cleanup.preserve-model-interval=10 --use-gpu=true --dir=/home/s1513472/lid/epochs13/nnet
['steps/nnet3/train_raw_dnn.py', '--stage=255', '--cmd=slurm.pl', '--trainer.optimization.proportional-shrink', '10', '--trainer.optimization.momentum=0.5', '--trainer.optimization.num-jobs-initial=3', '--trainer.optimization.num-jobs-final=3', '--trainer.optimization.initial-effective-lrate=0.001', '--trainer.optimization.final-effective-lrate=0.0001', '--trainer.optimization.minibatch-size=64', '--trainer.srand=123', '--trainer.max-param-change=2', '--trainer.num-epochs=13', '--trainer.dropout-schedule=0,0@0.20,0.1@0.50,0', '--trainer.shuffle-buffer-size=1000', '--egs.frames-per-eg=1', '--egs.dir=/home/s1513472/lid/baseline/nnet/egs', '--cleanup.remove-egs', 'false', '--cleanup.preserve-model-interval=10', '--use-gpu=true', '--dir=/home/s1513472/lid/epochs13/nnet']
Finished stage 4.
#### STAGE 7: Extracting X-vectors from the trained DNN. ####
./local/extract_xvectors.sh --cmd slurm.pl --mem 6G --use-gpu true --nj 32 --stage 0 /home/s1513472/lid/epochs13/nnet /home/s1513472/lid/baseline/enroll /home/s1513472/lid/epochs13/exp/xvectors_enroll
./local/extract_xvectors.sh --cmd slurm.pl --mem 6G --use-gpu true --nj 32 --stage 0 /home/s1513472/lid/epochs13/nnet /home/s1513472/lid/baseline/eval /home/s1513472/lid/epochs13/exp/xvectors_eval
Conda environment 'lid' active.
Conda environment 'lid' active.
./local/extract_xvectors.sh: using /home/s1513472/lid/epochs13/nnet/extract.config to extract xvectors
./local/extract_xvectors.sh: using /home/s1513472/lid/epochs13/nnet/extract.config to extract xvectors
./local/extract_xvectors.sh: extracting xvectors for /home/s1513472/lid/baseline/eval
./local/extract_xvectors.sh: extracting xvectors from nnet
./local/extract_xvectors.sh: extracting xvectors for /home/s1513472/lid/baseline/enroll
./local/extract_xvectors.sh: extracting xvectors from nnet
./local/extract_xvectors.sh: combining xvectors across jobs
./local/extract_xvectors.sh: computing mean of xvectors for each language
./local/extract_xvectors.sh: combining xvectors across jobs
./local/extract_xvectors.sh: computing mean of xvectors for each language
Finished stage 7.
#### STAGE 8: Training logistic regression classifier and classifying test utterances. ####
Finished stage 8.
#### STAGE 9: Calculating results. ####
Accuracy: 0.951 (19359/20349 classified correctly)
Confusion matrix:
    AR   BG   CH   CR   CZ   FR   GE   JA   KO   PL   PO   RU   SP   SW   TA   TH   TU   WU   VN  
AR  779  0    1    1    1    1    4    2    0    1    2    11   11   7    0    0    3    0    0   
BG  1    1202 0    5    0    0    0    0    0    11   2    10   0    0    0    0    1    0    0   
CH  0    0    1038 0    0    0    0    2    9    1    8    2    1    0    0    0    0    1    0   
CR  0    0    0    889  4    0    0    0    1    40   1    47   23   11   0    0    12   0    0   
CZ  0    0    0    0    1222 0    0    0    1    116  0    1    1    4    0    2    0    0    0   
FR  0    0    0    0    0    1081 0    0    0    2    0    1    0    0    0    0    1    2    0   
GE  31   0    8    2    12   0    1078 1    0    1    5    8    0    2    2    0    22   0    0   
JA  3    0    5    0    0    0    0    437  26   0    11   1    6    0    0    1    0    0    0   
KO  0    0    1    0    1    0    0    10   1147 0    0    0    9    1    0    1    0    1    0   
PL  0    1    0    0    0    0    2    0    0    1483 7    15   1    0    4    0    0    0    0   
PO  1    1    2    2    0    0    0    1    0    1    856  21   13   23   0    0    3    0    0   
RU  2    1    0    67   2    1    0    0    0    6    4    1589 9    3    0    0    4    12   0   
SP  7    0    0    6    0    1    1    0    5    2    26   30   1013 22   1    0    3    0    1   
SW  0    0    0    5    2    0    0    0    0    1    5    5    32   1296 0    0    1    0    0   
TA  0    0    0    0    0    0    0    0    0    0    0    0    0    0    414  0    0    0    0   
TH  1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1321 0    0    0   
TU  0    2    0    17   0    0    0    0    1    23   10   16   2    0    0    0    1018 0    1   
WU  0    0    6    0    0    0    0    0    0    0    1    1    1    2    0    0    0    336  0   
VN  0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    1160
C_primary value: 0.062
Finished stage 9.
